# ğŸ“˜ Prompt Engineering (2025) â€” Summary from Lee Boonstra's Official Guide

> â€œYou donâ€™t need to be a data scientist or machine learning engineer â€“ everyone can write a prompt.â€

---

## 1. What Is Prompt Engineering?

Prompt Engineering is the process of designing high-quality prompts that guide LLMs (like Gemini, GPT, Claude) to produce better output.

LLMs are just next-token predictors â€” they take your input and try to guess the next most likely word/token based on training data.

### ğŸ“Œ Why it matters:
- A poor prompt gives confusing or wrong output  
- A good prompt gives useful, accurate, and creative answers  
- Itâ€™s not just about what you ask, but how you ask  

---

## âš™ 2. LLM Output Configuration

LLMs have configurable settings that change how they respond:

### ğŸ”¹ Output Length
- Controls how long the answer will be.  
- Shorter responses = less cost, faster  
- Longer responses = more detailed, but heavier on performance  
- Doesnâ€™t affect style â€” just trims the response when limit is reached  

### ğŸ”¹ Temperature
> â€œControls the degree of randomness.â€

- 0 â†’ very deterministic (same answer every time)  
- 1.0 â†’ more creative, diverse responses  
- Think of it like a â€œcreativity levelâ€

### ğŸ”¹ Top-K & Top-P (Nucleus Sampling)
- Top-K = choose from top K likely next words (e.g., K=1 = only most likely one)  
- Top-P = choose from top words until the total probability reaches P (e.g., 0.95 = 95%)  
- You can combine Top-K, Top-P, and Temperature to balance creativity and control.

### âœ… Recommended starting values:

| Purpose       | Temperature | Top-P | Top-K |
|--------------|-------------|-------|-------|
| Balanced      | 0.2         | 0.95  | 30    |
| Creative      | 0.9         | 0.99  | 40    |
| Factual/Math  | 0.0         | â€”     | â€”     |

---

## ğŸ¯ 3. Prompting Techniques

### ğŸ”¹ Zero-Shot Prompting
Ask a direct question with no examples.  
**Example:**  
> â€œClassify this review as positive, neutral, or negative.â€

### ğŸ”¹ One-Shot / Few-Shot Prompting
Provide one or more examples in the prompt to guide the model.  
Used to teach the model your preferred structure or format.  
ğŸ§  *Few-shot = more reliable when task is complex.*

---

## ğŸ§© 4. System, Role, and Contextual Prompting

### ğŸ”¹ System Prompting
> â€œDefines the modelâ€™s fundamental capabilities and structure of output.â€  
Instruct the model to respond in a certain format.  
**Example:**  
> â€œOnly reply in JSON.â€

### ğŸ”¹ Role Prompting
> â€œAssigns a character or identity to the model.â€  
**Example:**  
> â€œAct as a travel guide.â€

### ğŸ”¹ Contextual Prompting
> â€œProvides background or current task context.â€  
**Example:**  
> â€œContext: my main file is using FastAPI as backend.â€

---

## âª 5. Step-Back Prompting

> â€œAsk a general question first, then use that as context to solve the specific task.â€

**Example (System Prompt):**  
> â€œAsk users to tell two numbers and then give them sum of those numbers.â€

**Chat Flow:**  
Bot: â€œTell me two numbers.â€  
User: â€œ2 and 4â€  
Bot: â€œsum = 6â€

ğŸ” *Purpose: Activate background knowledge before giving the answer.*

---

## ğŸ”— 6. Chain of Thought (CoT)

> â€œLetâ€™s think step by step.â€

Encourages the model to explain its reasoning before giving the final answer.

ğŸ’¡ Useful for:
- Math problems  
- Logic puzzles  
- Code generation  
- Planning tasks  

---

## ğŸ§  7. Self-Consistency

> â€œAsk the same question multiple times with slightly different outputs, and choose the most common answer.â€

âœ… *Benefit:* Improves accuracy by filtering out randomness  
âš  *Drawback:* More compute and time needed  

---

## ğŸŒ³ 8. Tree of Thoughts (ToT)

> â€œThink in multiple directions at once.â€ OR â€œAik problem ko solve krne ke multiple approachesâ€

The model explores multiple reasoning paths simultaneously (like a decision tree).  
Great for:
- Complex planning  
- Critical decision-making  

---

## ğŸ¤– 9. ReAct (Reason + Act)

> â€œModel reasons + takes actions using tools.â€

ReAct = Reasoning in natural language + Action via tools/API calls  
Useful for:
- Agents  
- Tool use  
- Search and retrieval workflows  

---

## âš¡ 10. APE â€“ Automatic Prompt Engineering

> â€œWrite a prompt that writes prompts.â€

1. Model generates prompt variations  
2. You score them using metrics like BLEU or ROUGE  
3. Then pick the best performing one  

---

## ğŸ’» 11. Code Prompting

âœ¨ **Types:**
- Generate code (Bash, Python, etc.)  
- Explain code (step-by-step)  
- Translate code (e.g., Bash â†’ Python)  
- Debug/Review (get suggestions or fixes)  

---

## ğŸ–¼ 12. Multimodal Prompting

> â€œUsing images + text + audio in prompts.â€

If the model supports it, you can combine images, audio, and text into a single prompt to provide richer context.

---

## ğŸ§  13. Best Practices for Prompt Engineering

âœ… Provide examples â€” especially for few-shot  
âœ… Keep it simple â€” short and clear wins  
âœ… Be specific â€” tell exactly what format/tone/output you want  
âœ… Use variables â€” like `{city}`, `{topic}` for flexibility  
âœ… Use positive instructions over negative constraints  
âœ… Document your prompts â€” log versions, outputs, and styles  

---

## ğŸ“Œ Final Summary (in plain words)

> â€œPrompt Engineering is not just about writing a question, it's about guiding the model step-by-step using structure, roles, tone, and clear examples. The goal is to get the most accurate, creative, or useful output for your task â€” and yes, you can do this even if youâ€™re not a developer.â€
